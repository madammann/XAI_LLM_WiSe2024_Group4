# About
This repository is used in the course "Explainability of Large Language Models", held by Nohayr Muhammad Abdelmoneim at the University Osnabr√ºck in Winter Semester 2024. This repository belongs to group 4 and the topic "Detecting and Understanding Vulnerabilities in Language Models via Mechanistic Interpretability".

# Getting started
In order to get started you first need to clone this repository to a directory on your drive which has enough space for the code and the model (approximately 0.7GB).

```git clone https://github.com/madammann/XAI_LLM_WiSe2024_Group4```

The repository from the paper by executing (from this folder address):

```git clone https://github.com/jgcarrasco/detecting-vulnerabilities-mech-interp```

Finally you will also need to install the packages from the environment.
For this either create a new conda environment and run the pip install, or create a new environment from the provided yml file.

With activated conda environment with python 3.13:
```pip install requirements.txt```

Or alternatively run:
```conda env create --file=environment.yml```

Or alternatively manually install the listed packages whilst adhering to the versions as strictly as possible.
After these steps you are ready to go and run the code from the repository yourself.

# Structure
ADD

# Contact
Fabienne Finas <ffinas@uni-osnabrueck.de>
Greta Bramow <gbramow@uni-osnabrueck.de>
Marlon Dammann <mdammann@uni-osnabrueck.de>
